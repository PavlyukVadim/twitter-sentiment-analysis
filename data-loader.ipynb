{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your keys at developer.twitter.com\n",
    "# And load them into file\n",
    "\n",
    "import json\n",
    "\n",
    "# Enter your keys/secrets as strings in the following fields\n",
    "credentials = {}\n",
    "credentials['CONSUMER_KEY'] = 'your_consumer_key'\n",
    "credentials['CONSUMER_SECRET'] = 'your_consumer_secret'\n",
    "credentials['ACCESS_TOKEN'] = 'your_access_token'\n",
    "credentials['ACCESS_SECRET'] = 'your_access_secret'\n",
    "\n",
    "# Save the credentials object to file\n",
    "with open('twitter_credentials.json', 'w') as file:\n",
    "    json.dump(credentials, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "with open('twitter_credentials.json', 'r') as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n",
    "\n",
    "import re\n",
    "# emoji_pattern = re.compile(\"[\"\n",
    "#     u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#     u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#     u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#     u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#     u\"\\U00002702-\\U000027B0\"\n",
    "#     u\"\\U000024C2-\\U0001F251\"\n",
    "#     \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# clean tweet text from links, mentions, etc\n",
    "def tweet_cleaner(tweet_text):\n",
    "    striped = tweet_text.strip()\n",
    "    filtered_links = re.sub(r'http\\S+', '', striped)\n",
    "    filtered_mentions = re.sub(r'@\\S+', '', filtered_links)\n",
    "    # filtered_emoji = emoji_pattern.sub(r'', filtered_mentions)\n",
    "    removed_dup_spaces = ' '.join(filtered_mentions.split())\n",
    "    return removed_dup_spaces\n",
    "# result = tweet_cleaner('  Ğ’Ğ¸ÑĞ½ĞµÑ‚ ğŸ˜© https://t.co/9GMRq47kdJ   @UkrainianMonbe1 @Nat__Mel 12')\n",
    "# print(result)\n",
    "\n",
    "# validation of tweet text\n",
    "def tweet_validator(tweet_text, min_len = 30, with_rt = False):\n",
    "    is_valid = True\n",
    "    not_valid = False\n",
    "\n",
    "    if (not with_rt and tweet_text.startswith('RT')):\n",
    "        return not_valid\n",
    "    if (len(tweet_text) < min_len):\n",
    "        return not_valid\n",
    "    return is_valid\n",
    "\n",
    "def get_tweets_dict(query, number_of_items):\n",
    "    dict_ = {\n",
    "        # 'user': [],\n",
    "        # 'date': [],\n",
    "        'text': [],\n",
    "        'query': [],\n",
    "        # 'favorite_count': []\n",
    "    }\n",
    "\n",
    "    query_q = query.get('q')\n",
    "    results = python_tweets.cursor(python_tweets.search, **query)\n",
    "\n",
    "    for result in results:\n",
    "        result_text = tweet_cleaner(result['text'])\n",
    "        if (not tweet_validator(result_text)):\n",
    "            continue\n",
    "\n",
    "        # dict_['user'].append(result['user']['screen_name'])\n",
    "        # dict_['date'].append(result['created_at'])\n",
    "        dict_['text'].append(result_text)\n",
    "        dict_['query'].append(query_q)\n",
    "        # dict_['favorite_count'].append(result['favorite_count'])\n",
    "\n",
    "        if (len(dict_['text']) >= number_of_items):\n",
    "            return dict_\n",
    "    return dict_\n",
    "\n",
    "\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "# import pandas as pd\n",
    "# query = { 'q': 'some query', 'lang': 'uk' }\n",
    "# df = pd.DataFrame(get_tweets_dict(query, 2))\n",
    "# df.sort_values(by='favorite_count', inplace = True, ascending = False)\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "text query\n0   Ğ’ÑĞµ Ñ‡Ğ°ÑÑ‚Ñ–ÑˆĞµ Ğ´ÑƒĞ¼Ğ°Ñ, Ñ‰Ğ¾ Ğ¼Ğ¸ Ğ½Ğµ Ğ·Ğ°ÑĞ»ÑƒĞ³Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ Ğ½Ğ° Ğ´Ğµ...     ğŸ˜©\n1             Ğ”Ğ–Ğ•ĞœĞ˜Ğ˜Ğ˜Ğ˜Ğ˜ĞĞĞĞĞĞğŸ˜©ğŸ˜©ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ¥ºğŸ¥ºğŸ¥ºğŸ˜©ğŸ˜©ğŸ˜©ğŸ˜©ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­     ğŸ˜©\n2   Ğ°Ğ³Ğ°, Ñ‚Ñ€Ğ¾ÑˆĞµÑ‡ĞºĞ¸ Ğ²Ğ¸Ñ‰Ğµ, Ğ°Ğ¶ 190 ÑĞ¼ ğŸ¤”Ğ½Ğ° Ñ„Ğ¾Ñ‚Ğ¾ Ğ²ÑÑ– ÑĞºĞ¾...     ğŸ˜©\n3                   Ğ”ÑƒĞ¶Ğµ Ğ½Ğ°Ğ´Ñ–ÑÑÑ ÑˆĞ¾ Ğ²Ğ¾Ğ½Ğ¾ Ñ‚Ğ¾Ğ³Ğ¾ Ğ²Ğ°Ñ€Ñ‚Ğµ ğŸ˜©     ğŸ˜©\n4   ĞĞ°Ğ° Ğ½Ñƒ ÑĞ°Ğ°Ğ°Ñˆ ğŸ˜©ğŸ˜©ğŸ˜©ğŸ’” Ğ¯ĞºĞ±Ğ¸ Ñ Ğ±ÑƒĞ»Ğ° Ğ± Ğ¿Ñ€ĞµĞ¿Ğ¾Ğ´Ğ¾Ğ¼ Ñ Ğ± Ğ¿...     ğŸ˜©\n5                 Ğ¾ÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ 700Ğº+ Ğ´Ğ¾ 80ĞºĞº Ğ½Ğ° Ğ¼Ğ°Ğ¿ĞµĞ¹ÑĞµ ğŸ˜©     ğŸ˜©\n6   Ğ¯Ğº Ğ·Ğ²ĞµÑÑ‚Ğ¸ ÑĞµĞ±Ğµ Ğ· Ñ€Ğ¾Ğ·ÑƒĞ¼Ñƒ (ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ³Ğ°Ğ¹Ğ´): ğŸ˜©ĞŸÑ€Ğ¸Ğ¹...     ğŸ˜©\n7   ĞĞµĞ·Ğ°Ğ±Ğ°Ñ€Ğ¾Ğ¼ Ğ½Ğ° ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¸Ñ… Ğ¼Ñ–ÑÑ†ÑÑ… Ğ²Ñ–Ğ´Ğ¿Ğ¾Ñ‡Ğ¸Ğ½ĞºÑƒ Ğ±Ñ–Ğ»...     ğŸ˜©\n8     Ğ—Ğ°Ğ±ÑƒĞ¶ĞºĞ¾: * Ğ¾Ğ±ÑĞ¸Ñ€Ğ°Ñ” Ñ…Ñ–Ğ¿ÑÑ‚ĞµÑ€Ñ–Ğ²* Ğ¯: ğŸ¤—ğŸ˜ğŸ¤©ğŸ˜©ğŸ¤§â¤ï¸ğŸ’•âœ¨ğŸ‘ğŸ‘ğŸ‘ŒğŸ’ªâœŠ     ğŸ˜©\n9   ÑƒĞ¶Ğ¾ Ğ±Ğ°Ñ‡Ñƒ ÑĞº Ğ·Ğ°ĞºÑ–Ğ½ÑƒĞ»Ñ– Ñ Ğ¿Ñ€Ğ°Ñ†Ğ¾ÑĞ½Ñ‹ Ñ‡Ğ°Ñ‚, Ğ±ĞµĞ· ÑƒĞºĞ°Ğ·Ğ°...     ğŸ˜©\n10  Ñ Ğ²Ğ¶Ğµ Ñ‡ĞµÑĞ½Ğ¾ Ğ·Ğ°Ğ¼Ğ°Ñ…Ğ½ÑƒĞ»Ğ°ÑÑŒ ÑÑ‚Ğ²Ğ¾Ñ€ÑĞ²Ğ°Ñ‚Ğ¸ Ğ½Ğ¾Ğ²Ñ– Ğ°ĞºĞ°ÑƒĞ½Ñ‚...     ğŸ˜©\n11   ĞœĞ°Ğ±ÑƒÑ‚ÑŒ, Ğ´Ğ¾ ĞºĞ°Ğ²Ğ¸ Ñ‚Ñ€ĞµĞ±Ğ° Ğ´Ğ¾Ğ´Ğ°Ñ‚Ğ¸ Ñ‡Ğ¾Ğ³Ğ¾ÑÑŒ Ğ¼Ñ–Ñ†Ğ½ĞµĞ½ÑŒĞºĞ¾Ğ³Ğ¾ğŸ˜©     ğŸ˜©\n12                Ñ…Ğ¾Ñ‡Ñƒ ÑĞµÑ‚ Ğ°Ğ»ÑŒĞ±Ğ¾Ğ¼Ğ¾Ğ² ÑĞ½Ğ³ Ñ„Ğ¾Ñ€ĞµĞ²ĞµÑ€ ğŸ˜£ğŸ˜©ğŸ˜ŸâœŠğŸ’”     ğŸ˜©\n13  Ğ’ Ğ½Ğ¸Ñ… ĞºĞ°Ğ¼Ğ±ĞµĞº Ğ½Ñ–Ğ±Ğ¸ Ğ²Ñ‡Ğ¾Ñ€Ğ° Ğ±ÑƒĞ², Ñ‚Ğ°Ğº? Ğ¯ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ğ»Ğ°...     ğŸ˜©\n14  Ğ¥Ğ¾Ñ‡Ñƒ Ñ‡Ğ¾Ğ³Ğ¾ÑÑŒ ÑĞ¾Ğ»Ğ¾Ğ´ĞµĞ½ÑŒĞºĞ¾Ğ³Ğ¾ Ğ´Ğ¾ Ñ‡Ğ°Ñ, Ğ°Ğ»Ğµ Ğ½Ñ–Ñ‡Ğ¾Ğ³Ğ¾ Ğ½Ğµ...     ğŸ˜©\n15  Ñ…Ğ¾Ñ‚Ñ–Ğ»Ğ° Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚Ğ¸ ÑĞµĞ»ĞµĞ½Ñ–ÑƒĞ¼ Ñ‚ĞµÑÑ‚Ğ¸Ğº, Ğ¿Ñ–Ğ´Ğ½ÑĞ»Ğ° ÑÑ‚Ğ°Ñ€Ñ–...     ğŸ˜©\n16  Ğ† Ñ†Ğµ Ñ‚Ğ¾Ğ¶Ğµ) Ğ¡Ğ°Ğ¼Ğ° ÑĞºĞ¾Ñ€Ğ¾ Ğ±ÑƒĞ´Ñƒ ÑˆĞ¾ÑÑŒ ÑˆÑƒĞºĞ°Ñ‚Ğ¸, Ñ‚Ğ¾Ğ¼Ñƒ Ğ¿...     ğŸ˜©\n17   Ğ!!! Ğ¦Ğµ Ñ Ñ‚Ğ°Ğº Ğ½Ğ° Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ñƒ Ñ—Ğ´Ñƒ Ğ¾ ÑˆĞ¾ÑÑ‚Ñ–Ğ¹ Ñ€Ğ°Ğ½ĞºÑƒ! ğŸ¤¦ğŸ˜©ğŸ˜©ğŸ˜©     ğŸ˜©\n18  Ğ¯ĞºĞµ Ğ·Ğ»Ğ¾ Ñ Ğ·Ñ€Ğ¾Ğ±Ğ¸Ğ»Ğ° Ñ‚Ğ¾Ğ¼Ñƒ ĞĞ¹Ğ´Ğ¾Ğ» Ğ§ĞµĞ¼Ğ¿Ñƒ? Ğ§Ğ¾Ğ¼Ñƒ Ğ²Ñ–Ğ½ Ğ·...     ğŸ˜©\n19            Ğ¡Ğ°Ğ¼Ğµ ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğµ ,ÑˆĞ¾ Ñ‚Ğ¾ Ñ–Ğ´Ñ”Ğ¹Ğ½Ñ– ÑÑ‚Ğ°Ñ…Ğ°Ğ½Ñ–Ğ²Ñ†Ñ–.ğŸ˜©     ğŸ˜©\n"
    }
   ],
   "source": [
    "query = {\n",
    "    'q': 'ğŸ˜©',\n",
    "    # 'result_type': 'popular',\n",
    "    'lang': 'uk',\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(get_tweets_dict(query, 20))\n",
    "# df.sort_values(by='favorite_count', inplace = True, ascending = False)\n",
    "# print(df)\n",
    "\n",
    "# import json\n",
    "with open('data/twitter-data-2.json', 'w', encoding='utf-8') as file:\n",
    "    df.to_json(file, orient='records', force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit0bb5f6c311484277905fd0791662116d",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}